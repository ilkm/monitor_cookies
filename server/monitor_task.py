# -*- coding: utf-8 -*-
"""
å®šæ—¶ä»»åŠ¡ï¼šç›‘æ§æŒ‡å®šç”¨æˆ·å’Œç«™ç‚¹çš„Fetch/XHRè¯·æ±‚
"""

import asyncio
from typing import Callable, Any
from fastapi import HTTPException
from urllib.parse import urlparse
import requests
import time
async def monitor_fetch_requests(browser_manager, user_id: str, site_code: str, url: str, on_request: Callable[[dict], Any]=None, duration: int=60):
    """
    ç›‘æ§æŒ‡å®šç”¨æˆ·å’Œç«™ç‚¹çš„Fetch/XHRè¯·æ±‚ï¼Œå¯åŠ¨æ—¶è‡ªåŠ¨è·³è½¬åˆ°urlã€‚
    :param browser_manager: BrowserManagerå®ä¾‹
    :param user_id: ç”¨æˆ·ID
    :param site_code: ç«™ç‚¹ç¼–ç 
    :param url: éœ€è¦ç›‘æ§çš„é¡µé¢URL
    :param on_request: æ¯æ¬¡æ•è·åˆ°è¯·æ±‚æ—¶çš„å›è°ƒå‡½æ•°ï¼Œå‚æ•°ä¸ºè¯·æ±‚ä¿¡æ¯å­—å…¸
    :param duration: ç›‘æ§æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
    :return: æ•è·åˆ°çš„æ‰€æœ‰è¯·æ±‚ä¿¡æ¯åˆ—è¡¨
    """
    page = await browser_manager.get_page(user_id, site_code, url)
    # è·³è½¬åˆ°æŒ‡å®šurlï¼ˆå¦‚æœget_pageæœªè‡ªåŠ¨è·³è½¬ï¼Œå¯å¼ºåˆ¶è·³è½¬ï¼‰
    try:
        if page.url != url:
            await page.goto(url, timeout=20000)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¡µé¢è·³è½¬å¤±è´¥: {e}")
    requests = []

    def handle_request(request):
        # åªç›‘æ§Fetch/XHRè¯·æ±‚
        if request.resource_type in ("fetch", "xhr"):
            info = {
                "url": request.url,
                "method": request.method,
                "headers": dict(request.headers),
                "post_data": request.post_data,
                "resource_type": request.resource_type,
                "timestamp": asyncio.get_event_loop().time()
            }
            requests.append(info)
            asyncio.create_task(print_all_headers(request, user_id, site_code, url))
            if on_request:
                on_request(info)

    page.on("request", handle_request)

    try:
        await asyncio.sleep(duration)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç›‘æ§è¯·æ±‚æ—¶å‡ºé”™: {e}")
    finally:
        page.off("request", handle_request)

    return requests 

async def print_all_headers(request, user_id, site_code, url):
    headers = await request.all_headers()
    # è·å–urlçš„åŸŸå print("[æœ€ç»ˆè¯·æ±‚å¤´]", headers)
    domain = urlparse(url).netloc
    # åˆ¤æ–­urlä¸­çš„åŸŸåæ˜¯å¦ä¸headersä¸­çš„hostä¸€è‡´,å¹¶ä¸”headersä¸­åŒ…å«cookie
    if ":authority" in headers and "cookie" in headers and domain in headers[":authority"]:
        cookie = headers["cookie"]
        send_cookie(cookie, user_id, site_code)

# å‘sites.json.config.cookie_apiå‘é€cookie
def send_cookie(cookie, user_id, site_code):
    print("ğŸ‚ğŸºåäº†ï¼Œå‘å°„cookie")
    from server.app import load_all_data
    data = load_all_data()
    config = data["config"]
    # ç±»å‹è½¬æ¢ï¼Œç¡®ä¿user_idå’Œsite_codeä¸ºint
    try:
        user_id_int = int(user_id)
        site_code_int = int(site_code)
    except Exception as e:
        print(f"[ç±»å‹è½¬æ¢é”™è¯¯] user_idæˆ–site_codeæ— æ³•è½¬æ¢ä¸ºint: {e}")
        return
    # è·å–ç”¨æˆ·é…ç½®
    user_config = next((user for user in data["users"] if int(user["user_id"]) == user_id_int), None)
    if not user_config:
        print(f"[é”™è¯¯] æœªæ‰¾åˆ°user_id={user_id}çš„ç”¨æˆ·é…ç½®")
        return
    # è·å–ç«™ç‚¹é…ç½®
    site_config = next((site for site in user_config["sites"] if int(site["code"]) == site_code_int), None)
    if not site_config:
        print(f"[é”™è¯¯] æœªæ‰¾åˆ°site_code={site_code}çš„ç«™ç‚¹é…ç½®")
        return
    # å‘sites.json.config.cookie_apiå‘é€cookie
    url = config["cookie_api"]
    # queryåæ‹¼æ¥æ—¶é—´æˆ³å‚æ•°ï¼Œçº³ç§’
    url = f"{url}?t={int(time.time() * 1000000000)}"
    response = requests.post(url, json={"cookies": cookie, "account_type": site_config["account_type"], "code": site_code_int})
    print(f"[å‘é€cookie] å“åº”: {response.status_code} {response.text}")
    print("-" * 60)
    return response.json()